{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7c6302",
   "metadata": {},
   "source": [
    "# Sketch Detection CNN Training\n",
    "\n",
    "This notebook trains a Convolutional Neural Network to detect UI elements from canvas sketches.\n",
    "\n",
    "## Objectives\n",
    "- Build a CNN classifier for UI element types (button, input, container, text)\n",
    "- Train on labeled sketch dataset\n",
    "- Evaluate with accuracy, precision, recall, confusion matrix\n",
    "- Export model to `backend/models/sketch_detector.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e759fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "CLASS_NAMES = ['button', 'input', 'container', 'text', 'background']\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = '../datasets/sketches'\n",
    "LABELS_DIR = '../datasets/labels'\n",
    "MODEL_OUTPUT = '../../backend/models/sketch_detector.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "def load_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # TODO: Implement dataset loading\n",
    "    # - Read images from DATASET_DIR\n",
    "    # - Read corresponding labels from LABELS_DIR\n",
    "    # - Extract element regions and classify\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load data\n",
    "X, y = load_dataset()\n",
    "print(f\"Dataset shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(*IMG_SIZE, 1)),\n",
    "        \n",
    "        # Convolutional layers\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(len(CLASS_NAMES), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a36143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and confusion matrix\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=CLASS_NAMES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(MODEL_OUTPUT)\n",
    "print(f\"\\nModel saved to: {MODEL_OUTPUT}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
